{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:48:49.978634293Z",
     "start_time": "2023-07-23T14:48:49.964663310Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/root/projects/PythonProjects/ip-dual-encoder-factorization-machine')\n",
    "os.chdir('/root/projects/PythonProjects/ip-dual-encoder-factorization-machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "my_model_config = dict()\n",
    "my_model_config['nuser'] = 19672 + 1  # NUM_USERS, 0th token is the padding token\n",
    "my_model_config['nitem'] = 47844 + 1  # NUM_ITEMS, 0th token is the padding token\n",
    "my_model_config['d_model'] = 768\n",
    "my_model_config['nhead'] = 4  # 8  #12\n",
    "my_model_config['d_hid'] = 1024  # 2048  # dim_feedforward\n",
    "my_model_config['dropout'] = 0.1  # 0.3  # 0.2  # 0.1\n",
    "my_model_config['nlayers'] = 2  # 1  # 3  # 6  #12\n",
    "my_model_config['checkpoint'] = 'bert-base-cased'  # 'jjzha/jobbert-base-cased'\n",
    "# Use 'bert-base-cased'! 'jjzha/jobbert-base-cased' is problematic, causing BCEloss not decreasing!\n",
    "\n",
    "my_model_config['using_cross_attention'] = False  # False # Not useful"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:32:54.814687659Z",
     "start_time": "2023-07-23T14:32:54.805017404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from model_ddp_trainer.model import DualEncoderAttentionNetwork\n",
    "\n",
    "model = DualEncoderAttentionNetwork(**my_model_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:32:58.929325528Z",
     "start_time": "2023-07-23T14:32:55.913394524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:43:29.830778015Z",
     "start_time": "2023-07-23T14:43:29.815161174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/root/tmp/tmp/aws-model-training/model_checkpoint_training_steps#26000_run-20230722-224841.pt', map_location=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:33:02.757534507Z",
     "start_time": "2023-07-23T14:33:01.537618352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:39:33.025224155Z",
     "start_time": "2023-07-23T14:39:32.868883449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "DualEncoderAttentionNetwork(\n  (job_feature_embedding_layer): JobFeatureEmbeddings(\n    (metadata_lookup_table): Embedding(47845, 4, padding_idx=0)\n    (metadata_embedding_layers): ModuleList(\n      (0): Embedding(84, 768, padding_idx=0)\n      (1): Embedding(31, 768, padding_idx=0)\n      (2): Embedding(306, 768, padding_idx=0)\n      (3): Embedding(5, 768, padding_idx=0)\n    )\n  )\n  (job_embedding_layer): JobEmbedding(\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (job_id_embedding_layer): Embedding(47845, 768, padding_idx=0)\n    (job_feature_embedding_layer): JobFeatureEmbeddings(\n      (metadata_lookup_table): Embedding(47845, 4, padding_idx=0)\n      (metadata_embedding_layers): ModuleList(\n        (0): Embedding(84, 768, padding_idx=0)\n        (1): Embedding(31, 768, padding_idx=0)\n        (2): Embedding(306, 768, padding_idx=0)\n        (3): Embedding(5, 768, padding_idx=0)\n      )\n    )\n  )\n  (item_encoder): ItemEncoder(\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (job_embedding_layer): JobEmbedding(\n      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (job_id_embedding_layer): Embedding(47845, 768, padding_idx=0)\n      (job_feature_embedding_layer): JobFeatureEmbeddings(\n        (metadata_lookup_table): Embedding(47845, 4, padding_idx=0)\n        (metadata_embedding_layers): ModuleList(\n          (0): Embedding(84, 768, padding_idx=0)\n          (1): Embedding(31, 768, padding_idx=0)\n          (2): Embedding(306, 768, padding_idx=0)\n          (3): Embedding(5, 768, padding_idx=0)\n        )\n      )\n    )\n    (job_feature_embedding_layer): JobFeatureEmbeddings(\n      (metadata_lookup_table): Embedding(47845, 4, padding_idx=0)\n      (metadata_embedding_layers): ModuleList(\n        (0): Embedding(84, 768, padding_idx=0)\n        (1): Embedding(31, 768, padding_idx=0)\n        (2): Embedding(306, 768, padding_idx=0)\n        (3): Embedding(5, 768, padding_idx=0)\n      )\n    )\n    (bert_encoder): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n  )\n  (user_encoder): UserEncoder(\n    (transformer_encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (user_embedding_layer): UserEmbedding(\n      (dropout): Dropout(p=0.1, inplace=False)\n      (user_ids_embedding_layer): Embedding(19673, 768, padding_idx=0)\n    )\n    (job_embedding_layer): JobEmbedding(\n      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (job_id_embedding_layer): Embedding(47845, 768, padding_idx=0)\n      (job_feature_embedding_layer): JobFeatureEmbeddings(\n        (metadata_lookup_table): Embedding(47845, 4, padding_idx=0)\n        (metadata_embedding_layers): ModuleList(\n          (0): Embedding(84, 768, padding_idx=0)\n          (1): Embedding(31, 768, padding_idx=0)\n          (2): Embedding(306, 768, padding_idx=0)\n          (3): Embedding(5, 768, padding_idx=0)\n        )\n      )\n    )\n  )\n  (bipolar_attention): BipolarScaledDotProductAttention()\n  (fully_connected_block): Sequential(\n    (0): Linear(in_features=1536, out_features=1024, bias=True)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Linear(in_features=1024, out_features=512, bias=True)\n    (3): LeakyReLU(negative_slope=0.01)\n    (4): Linear(in_features=512, out_features=256, bias=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Linear(in_features=256, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:40:19.188609564Z",
     "start_time": "2023-07-23T14:40:19.163385080Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:42:14.566190895Z",
     "start_time": "2023-07-23T14:42:14.542465614Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# dataset_dict_s3_path = '/opt/project/data/input_processed_output(二分类可行，文本是否有问题不确定)/final_dataset_dict/'\n",
    "dataset_dict_s3_path = '/root/projects/PythonProjects/ip-dual-encoder-factorization-machine/data/input_processed_output(P1N1)/final_dataset_dict/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:42:20.438546758Z",
     "start_time": "2023-07-23T14:42:20.427470307Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset_dict = DatasetDict.load_from_disk(dataset_dict_path=dataset_dict_s3_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:42:21.387608638Z",
     "start_time": "2023-07-23T14:42:21.041836723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "from model_ddp_trainer.custom_collate_function import CustomCollateFunc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer_checkpoint = my_model_config['checkpoint']\n",
    "bert_tokenizer_model_max_length = 512\n",
    "custom_collate_function = CustomCollateFunc(tokenizer_checkpoint, bert_tokenizer_model_max_length)\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset_dict[\"test\"], batch_size=batch_size, collate_fn=custom_collate_function, pin_memory=True,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    # sampler=DistributedSampler(dataset_dict[\"valid\"], shuffle=False, drop_last=True)  # 504114 % (64 * 4) == 50 samples\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:47:13.706893067Z",
     "start_time": "2023-07-23T14:47:12.390424774Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryAUROC, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "metric_auroc = BinaryAUROC().to(device)\n",
    "metric_precision = BinaryPrecision().to(device)\n",
    "metric_recall = BinaryRecall().to(device)\n",
    "metric_f1score = BinaryF1Score().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T15:00:12.008353831Z",
     "start_time": "2023-07-23T15:00:11.997595815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2930 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c4d7b1c3fb241f19aeb262424bbfc3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/devenv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:296: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from model_ddp_trainer.ddp_trainer import get_features, get_label\n",
    "\n",
    "model.eval()\n",
    "metric_auroc.reset()\n",
    "metric_precision.reset()\n",
    "metric_recall.reset()\n",
    "metric_f1score.reset()\n",
    "\n",
    "avg_test_loss = 0\n",
    "test_losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in tqdm(test_dataloader):\n",
    "        output = model(**get_features(test_batch, device))\n",
    "        labels = get_label(test_batch, device)\n",
    "        test_loss = criterion(output, labels)\n",
    "\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        metric_auroc.update(preds=output, target=labels.int())\n",
    "        metric_precision.update(preds=output, target=labels.int())\n",
    "        metric_recall.update(preds=output, target=labels.int())\n",
    "        metric_f1score.update(preds=output, target=labels.int())\n",
    "    avg_test_loss = sum(test_losses) / len(test_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T15:14:50.637927411Z",
     "start_time": "2023-07-23T15:00:29.805157789Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "metrics = {\n",
    "            'test Loss': avg_test_loss.item(),\n",
    "            'test AUC': metric_auroc.compute().item(),\n",
    "            'test Precision': metric_precision.compute().item(),\n",
    "            'test Recall': metric_recall.compute().item(),\n",
    "            'test F1Score': metric_f1score.compute().item(),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T15:16:45.170324858Z",
     "start_time": "2023-07-23T15:16:45.060532225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{'test Loss': 0.2982197403907776,\n 'test AUC': 0.9672754406929016,\n 'test Precision': 0.9273624420166016,\n 'test Recall': 0.8761467933654785,\n 'test F1Score': 0.9010273814201355}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T15:16:50.147727638Z",
     "start_time": "2023-07-23T15:16:50.112868339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
